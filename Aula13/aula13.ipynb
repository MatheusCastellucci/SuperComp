{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega - Aula 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aluno: Matheus Raffaelle Nery Castellucci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Schedules</u>\n",
    "\n",
    "1. Execute o código com diferentes schedulers (static, dynamic, guided, auto) e registre o tempo necessário para cada execução, faça ao menos 3 execuções para cada teste.\n",
    "2. Compare os tempos médios de execução para cada scheduler.\n",
    "\n",
    "### Perguntas de Análise:\n",
    "\n",
    "* Qual scheduler apresentou o menor tempo médio? \n",
    "\n",
    "        O schedule(static) apresentou o menor tempo médio de execução, com 2.61422e-06 segundos\n",
    "\n",
    "* Algum scheduler teve variações significativas entre as execuções? Se sim, por quê?\n",
    "        \n",
    "        Sim, os agendamentos dynamic e guided mostraram variações significativas na forma como as iterações foram distribuídas entre as threads e nos tempos de execução. Isso ocorre porque esses agendamentos são adaptativos e distribuem as iterações em tempo de execução com base na disponibilidade das threads.\n",
    "\n",
    "* Alguma característica específica do trabalho (como carga de dados, balanceamento) parece ter influenciado o comportamento de um scheduler em particular?\n",
    "\n",
    "        Carga de Dados: O número de iterações n = 64 é relativamente pequeno. Com poucos elementos para processar, a sobrecarga de gerenciamento de tarefas pode ter um impacto maior em agendamentos adaptativos (dynamic e guided), resultando em tempos de execução ligeiramente mais longos.\n",
    "\n",
    "        Balanceamento: No caso dos agendamentos static, o balanceamento é garantido pela distribuição uniforme das iterações. Já nos agendamentos dynamic e guided, o balanceamento depende da ordem em que as threads completam suas tarefas, o que pode levar a variações.\n",
    "\n",
    "        Granularidade: Para dynamic, 1, a granularidade é muito fina, o que aumenta a sobrecarga de gerenciamento de tarefas. Isso explica por que o tempo de execução é maior do que para blocos mais grossos, como dynamic, 4 ou dynamic, 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Calculo do PI</u>\n",
    "\n",
    "1. Paralelize o cálculo recursivo de Pi usando parallel for e meça o tempo de execução. Execute o código pelo menos 3 vezes com diferentes valores de MIN_BLK e registre os tempos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_MIN_BLK = [(1024 * 1024 * 256), (1024 * 1024 * 512), (1024 * 1024 * 1024), ]\n",
    "\n",
    "tempos_exec_seconds = [1.37867253925651, 1.3731563007459, 1.35357125010341]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Paralelize o cálculo recursivo de Pi usando #pragma omp task e meça o tempo de execução. Execute o código pelo menos 3 vezes com diferentes números de tarefas e registre os tempos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeros_tarefas = [8, 16, 32, 64]\n",
    "\n",
    "tempos_exec_seconds = [1.68918477464467, 1.67343963310122, 1.48120587132871, 1.45651693921536]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perguntas de Análise:\n",
    "\n",
    "* Qual abordagem (parallel for ou tasks) apresentou melhor desempenho?\n",
    "\n",
    "        A abordagem parallel for apresentou melhor desempenho médio, com tempos de execução consistentemente menores.\n",
    "\n",
    "* O valor de MIN_BLK ou o número de tarefas influenciou significativamente o tempo de execução?\n",
    "\n",
    "        Sim, houveram influências significativas, para a abordagem com parallel for, conforme o valor de MIN_BLK aumentou, o tempo de execução diminuiu ligeiramente. Isso indica que os blocos de trabalho maiores reduziram a sobrecarga de gerenciamento de paralelismo, resultando em uma execução mais eficiente. Para a abordagem com tasks, os tempos de execução foram melhores conforme o número de tarefas aumentou (especialmente quando passou de 16 para 64), mostrando que ter mais tarefas disponíveis para distribuição entre as threads melhorou o desempenho.                \n",
    "\n",
    "* Alguma abordagem teve variação maior entre execuções? Por quê?\n",
    "\n",
    "        A abordagem com tasks apresentou maior variação entre execuções. Isso ocorre porque o uso de tarefas envolve mais decisões dinâmicas em relação à distribuição de carga, o que pode levar a inconsistências no tempo de execução, especialmente quando o número de tarefas é baixo. Quanto menor o número de tarefas, maior a chance de haver desequilíbrio na distribuição da carga de trabalho entre as threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Manipulação de Efeitos Colaterais no Vetor</u>\n",
    "\n",
    "1. Paralelize o código que modifica um vetor com #pragma omp critical para evitar acessos simultâneos ao vetor e registre os tempos de execução. Execute o código pelo menos 3 vezes e registre os tempos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_exec_critical = [0.00161403, 0.00153716, 0.00165568, 0.00177177, 0.00170105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Modifique o código para pré-alocar a memória do vetor, evitando o uso de push_back, e meça o tempo. Execute o código pelo menos 3 vezes e registre os tempos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempos_exec_memoria = [0.0151829, 0.0290922, 0.0271457, 0.0275757]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perguntas de Análise:\n",
    "\n",
    "* Qual abordagem teve melhor desempenho: omp critical ou pré-alocação de memória?\n",
    "\n",
    "        A abordagem com omp critical teve um desempenho significativamente melhor, com tempos de execução muito mais baixos do que a abordagem com pré-alocação de memória.\n",
    "\n",
    "* O uso de omp critical adicionou muito overhead? Como você pode justificar isso?\n",
    "\n",
    "        Não, o uso de omp critical não adicionou muito overhead. Os tempos de execução para essa abordagem foram consistentemente baixos. Isso sugere que, apesar do uso da região crítica, o impacto no desempenho foi mínimo, provavelmente devido ao fato de que a operação protegida (adicionar um elemento ao vetor) é relativamente rápida e o tamanho do problema (N=10000) não era tão grande a ponto de introduzir uma contenção significativa.\n",
    "\n",
    "* A ordem dos dados no vetor foi mantida em ambas as abordagens?\n",
    "        \n",
    "        Sim, a ordem dos dados foi mantida em ambas as abordagens. No caso do omp critical, as operações de inserção foram realizadas em ordem sequencial, garantindo que os elementos fossem inseridos na ordem correta. Na abordagem com pré-alocação, cada thread escreveu em um índice específico do vetor (vec[i]), o que preservou a ordem dos elementos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Conclusão</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Resuma as principais conclusões com base nos resultados obtidos nos testes.\n",
    "\n",
    "    Os testes indicaram que a abordagem com parallel for geralmente apresentou melhor desempenho em termos de tempo de execução, especialmente em cenários onde a carga de trabalho era uniformemente distribuída. O uso de tasks, por outro lado, mostrou-se mais vantajoso em situações com divisões recursivas de tamanho variável, embora introduzisse uma maior sobrecarga devido ao gerenciamento dinâmico das tarefas. O ajuste do parâmetro MIN_BLK influenciou significativamente o desempenho do parallel for, enquanto o número de tarefas máximas teve um impacto notável nos testes com tasks. Para operações que envolvem modificações em estruturas compartilhadas, técnicas de sincronização cuidadosas são essenciais para evitar condições de corrida e manter a integridade dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Qual abordagem geral você considera mais eficiente para problemas recursivos e com efeitos colaterais?\n",
    "\n",
    "    Para problemas recursivos, a abordagem com tasks é geralmente mais eficiente, pois permite que a carga de trabalho seja dividida de forma adaptativa, distribuindo as tarefas conforme a disponibilidade das threads. Essa abordagem é particularmente eficaz quando a recursão cria subproblemas de tamanhos variados. No entanto, quando há efeitos colaterais, como modificações em estruturas de dados compartilhadas, é necessário usar técnicas de sincronização, como omp critical ou variáveis atômicas, para garantir a correção dos dados, mesmo que isso possa reduzir o desempenho devido à sobrecarga introduzida pela sincronização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Alguma técnica apresentou resultados inesperados? O que poderia explicar isso?\n",
    "\n",
    "    Sim, a técnica de pré-alocação de memória apresentou tempos de execução mais altos do que o esperado, especialmente em comparação com o uso de omp critical. Isso pode ser explicado pelo aumento da complexidade do gerenciamento de memória em um ambiente paralelo, onde o acesso simultâneo a diferentes posições do vetor pode ter causado mais interferência no cache e competição por recursos de memória. Além disso, a distribuição das operações de escrita pode ter levado a um uso ineficiente da memória, resultando em tempos de execução superiores aos previstos. Isso destaca a importância de entender o impacto das operações de memória e sincronização no desempenho de programas paralelos."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
