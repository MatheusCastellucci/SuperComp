{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega - Aula 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aluno: Matheus Raffaelle Nery Castellucci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Parte 1</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000000\n",
    "\n",
    "valor_estimado_pi = [3.14141, 3.14155, 3.14188, 3.1416, 3.14167]\n",
    "\n",
    "tempo_execucao = [2.95323, 2.94182, 3.06859, 2.9634, 2.93169]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para gerar os números aleatórios usei o std::rand(), que não é o melhor gerador para isso. Além do mais, ele gera apenas números inteiros, então tive que dividir por `RAND_MAX`para manter os valores entre 0 e 1.\n",
    "\n",
    "* A implementação sequencial não apresentou dificuldades, mas vale ressaltar que std::rand() não é thread-safe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Parte 2</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000000\n",
    "\n",
    "valor_estimado_pi = [3.14141, 3.14192, 3.14141, 3.14157, 3.14183]\n",
    "\n",
    "tempo_execucao = [24.2738, 25.1656, 22.9473, 25.255, 25.293]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O problema principal na parelização é que a função `std::rand()` não é thread-safe, isso quer dizer que várias threads acessando simultaneamente o mesmo gerador de números aleatórios podem resultar em conflitos e, possivelmente, na geração de sequências repetidas ou incorretas de números aleatórios.\n",
    "\n",
    "* Para evitar conflitos, o código foi paralelizado com uma operação de redução `(reduction(+:pontosDentroDoCirculo))`, o que garante que a variável de contagem dos pontos dentro do círculo seja atualizada de forma segura.\n",
    "\n",
    "* O impacto do método utilizado para contornar o problema foi maior do que o esperado e isso causou um aumento enorme (10x) no tempo de execução. Apesar disso, acredito que a parelização poderia se mostrar como uma alternativa possivel para a melhoria de tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Parte 3</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000000\n",
    "\n",
    "valor_estimado_pi = [3.14183, 3.14151, 3.14163, 3.14158, 3.14154]\n",
    "\n",
    "tempo_execucao = [0.43968, 0.434633, 0.576623, 0.456948, 0.44216]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A principal mudança nesta etapa foi associar a cada thread seu próprio gerador de números aleatórios utilizando o std::mt19937, com sementes diferentes para cada thread, baseadas no número da thread e no tempo atual. Isso resolve o problema de threads compartilhando o mesmo gerador, o que poderia gerar resultados repetidos ou até comprometer a qualidade dos números aleatórios. Ele é mais adequado para aplicações modernas e é muito mais eficiente e confiável em ambientes paralelos. Além disso, sua qualidade estatística é superior à de std::rand().\n",
    "\n",
    "* Valor de PI se manteu constante por todos os testes feitos. E o tempo de execução melhorou muito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Conclusão e Comparação</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Versão                              | Valor Estimado de Pi | Tempo de Execução (segundos) |\n",
    "|-------------------------------------|----------------------|------------------------------|\n",
    "| Sequencial (Parte 1)                | 3.14141 - 3.14167    | 2.93169 - 3.06859            |\n",
    "| Primeira Paralelização (Parte 2)     | 3.14141 - 3.14183    | 22.9473 - 25.293             |\n",
    "| Paralelização com Melhoria (Parte 3) | 3.14151 - 3.14183    | 0.434633 - 0.576623          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Houve uma melhoria significativa no tempo de execução entre a versão sequencial e as versões paralelas?\n",
    "\n",
    "* Sim, houve uma melhoria drástica no tempo de execução na Parte 3. A versão sequencial levou cerca de 2.9 a 3 segundos para completar a execução, enquanto a versão final paralelizada (com otimização da geração de números aleatórios) reduziu esse tempo para menos de 0.6 segundos. Isso representa uma melhoria significativa, especialmente considerando o número de pontos (N=100000000). A Parte 2 foi, curiosamente, mais lenta que a versão sequencial, provavelmente devido à ineficiência de std::rand() em um ambiente paralelo, o que causou gargalos.\n",
    "\n",
    "### 2. A estimativa de pi permaneceu precisa em todas as versões?\n",
    "\n",
    "* Sim, a estimativa de pi foi bastante precisa em todas as versões. O valor variou em torno de 3.14141 a 3.14183, o que está muito próximo do valor real de pi (3.14159). Isso mostra que a paralelização e as otimizações não comprometeram a precisão do algoritmo\n",
    "\n",
    "### 3. Quais foram os maiores desafios ao paralelizar o algoritmo, especialmente em relação aos números aleatórios?\n",
    "\n",
    "* O maior desafio foi a geração de números aleatórios em um ambiente paralelo. Na Parte 2, o uso de std::rand() não foi eficiente, uma vez que essa função não é thread-safe e causou competição entre threads. Isso gerou uma redução de desempenho. Na Parte 3, resolvemos esse problema ao atribuir um gerador de números aleatórios separado para cada thread (std::mt19937), garantindo que não houvesse conflitos e que cada thread pudesse trabalhar de forma independente. Essa mudança resultou em um grande ganho de desempenho.\n",
    "\n",
    "### 4. O uso de threads trouxe benefícios claros para este problema específico?\n",
    "\n",
    "* Sim, o uso de threads, especialmente na Parte 3, trouxe benefícios claros. A melhoria no tempo de execução foi impressionante, reduzindo-o para menos de 0.6 segundos, em comparação com a execução sequencial que levou cerca de 3 segundos. Isso demonstra que a paralelização foi altamente eficaz para um problema que envolve um grande número de cálculos independentes, como é o caso do algoritmo de Monte Carlo."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
